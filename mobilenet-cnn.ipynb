{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:21:18.409805Z","iopub.execute_input":"2021-12-16T11:21:18.410155Z","iopub.status.idle":"2021-12-16T11:21:18.446206Z","shell.execute_reply.started":"2021-12-16T11:21:18.410067Z","shell.execute_reply":"2021-12-16T11:21:18.445275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd \nfrom skimage import io\nfrom skimage import color\nfrom PIL import Image\nimport PIL.Image\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dask.array.image import imread\nfrom dask import bag, threaded\nfrom dask.diagnostics import ProgressBar\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nfrom keras import backend as K\nfrom keras.layers.core import Dense, Activation\n\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import imagenet_utils\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom IPython.display import Image\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten,Input\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing import image \nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras import optimizers\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:25:42.633055Z","iopub.execute_input":"2021-12-16T11:25:42.633507Z","iopub.status.idle":"2021-12-16T11:25:42.644719Z","shell.execute_reply.started":"2021-12-16T11:25:42.633466Z","shell.execute_reply":"2021-12-16T11:25:42.643748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.getcwd()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:25:48.728779Z","iopub.execute_input":"2021-12-16T11:25:48.729059Z","iopub.status.idle":"2021-12-16T11:25:48.737409Z","shell.execute_reply.started":"2021-12-16T11:25:48.729028Z","shell.execute_reply":"2021-12-16T11:25:48.736279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver_details = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv',na_values='na')\nprint(driver_details.head(5))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:26:48.695932Z","iopub.execute_input":"2021-12-16T11:26:48.696214Z","iopub.status.idle":"2021-12-16T11:26:48.743528Z","shell.execute_reply.started":"2021-12-16T11:26:48.696183Z","shell.execute_reply":"2021-12-16T11:26:48.742476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Getting all the images\n\ntrain_image = []\nimage_label = []\n\n\nfor i in range(10):\n    print('now we are in the folder C',i)\n    imgs = os.listdir(\"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i))\n    for j in range(len(imgs)):\n    #for j in range(100):\n        img_name = \"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i)+\"/\"+imgs[j]\n        img = cv2.imread(img_name)\n        #img = color.rgb2gray(img)\n        img = img[50:,120:-50]\n        img = cv2.resize(img,(224,224))\n        label = i\n        driver = driver_details[driver_details['img'] == imgs[j]]['subject'].values[0]\n        train_image.append([img,label,driver])\n        image_label.append(i)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:26:49.603199Z","iopub.execute_input":"2021-12-16T11:26:49.603874Z","iopub.status.idle":"2021-12-16T11:33:12.17432Z","shell.execute_reply.started":"2021-12-16T11:26:49.603826Z","shell.execute_reply":"2021-12-16T11:33:12.173372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Randomly shuffling the images\n\nimport random\nrandom.shuffle(train_image)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:12.176175Z","iopub.execute_input":"2021-12-16T11:33:12.176475Z","iopub.status.idle":"2021-12-16T11:33:12.207126Z","shell.execute_reply.started":"2021-12-16T11:33:12.176433Z","shell.execute_reply":"2021-12-16T11:33:12.205758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driv_selected = ['p050', 'p015', 'p022', 'p056']","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:12.208864Z","iopub.execute_input":"2021-12-16T11:33:12.210158Z","iopub.status.idle":"2021-12-16T11:33:12.219495Z","shell.execute_reply.started":"2021-12-16T11:33:12.21011Z","shell.execute_reply":"2021-12-16T11:33:12.218527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Splitting the train and test\n\nX_train= []\ny_train = []\nX_test = []\ny_test = []\nD_train = []\nD_test = []\n\nfor features,labels,drivers in train_image:\n    if drivers in driv_selected:\n        X_test.append(features)\n        y_test.append(labels)\n        D_test.append(drivers)\n    \n    else:\n        X_train.append(features)\n        y_train.append(labels)\n        D_train.append(drivers)\n    \nprint (len(X_train),len(X_test))\nprint (len(y_train),len(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:12.222529Z","iopub.execute_input":"2021-12-16T11:33:12.223027Z","iopub.status.idle":"2021-12-16T11:33:12.253378Z","shell.execute_reply.started":"2021-12-16T11:33:12.222981Z","shell.execute_reply":"2021-12-16T11:33:12.252023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Converting images to nparray. Encoding the Y\n\nX_train = np.array(X_train).reshape(-1,224,224,3)\nX_test = np.array(X_test).reshape(-1,224,224,3)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n\nprint (X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:12.255301Z","iopub.execute_input":"2021-12-16T11:33:12.255768Z","iopub.status.idle":"2021-12-16T11:33:13.498651Z","shell.execute_reply.started":"2021-12-16T11:33:12.255667Z","shell.execute_reply":"2021-12-16T11:33:13.497724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n# base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:13.500041Z","iopub.execute_input":"2021-12-16T11:33:13.500359Z","iopub.status.idle":"2021-12-16T11:33:17.63279Z","shell.execute_reply.started":"2021-12-16T11:33:13.500311Z","shell.execute_reply":"2021-12-16T11:33:17.631744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=base_model.output\nx=GlobalAveragePooling2D()(x)\n\n# x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n\n# x = Dropout(0.1)(x) # ****reduce dropout \n\n# x=Dense(1024,activation='relu')(x) #dense layer 2\n\n# x = BatchNormalization()(x)\n# x = Dropout(0.5)(x)\n\n# x=Dense(512,activation='relu')(x) #dense layer 3\n\npreds=Dense(10,activation='softmax')(x) #final layer with softmax activation\n\nmodel = Model(inputs=base_model.input, outputs=preds)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.63461Z","iopub.execute_input":"2021-12-16T11:33:17.635665Z","iopub.status.idle":"2021-12-16T11:33:17.726434Z","shell.execute_reply.started":"2021-12-16T11:33:17.635616Z","shell.execute_reply":"2021-12-16T11:33:17.724255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import optimizers  \nimport tensorflow as tf\n\n#adam = optimizers.Adam(lr=0.001) #tried 0.0005 - too slow and didn't converge\nsgd = tf.keras.optimizers.SGD(lr = 0.005) # try 0.01 - didn't converge and 0.005 , 0.001 best acc of 11%\n\nmodel.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy']) # create object\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:43:25.399759Z","iopub.execute_input":"2021-12-16T11:43:25.400048Z","iopub.status.idle":"2021-12-16T11:43:25.420877Z","shell.execute_reply.started":"2021-12-16T11:43:25.400015Z","shell.execute_reply":"2021-12-16T11:43:25.419864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\n\ncheckpointer = ModelCheckpoint('mobilenet_sgd_nolayers.hdf5', verbose=1, save_best_only=True)\nearlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n\ndatagen = ImageDataGenerator(\n    height_shift_range=0.5,\n    width_shift_range = 0.5,\n    zoom_range = 0.5,\n    rotation_range=30\n        )\n#datagen.fit(X_train)\ndata_generator = datagen.flow(X_train, y_train, batch_size = 64)\n\n# Fits the model on batches with real-time data augmentation:\nmobilenet_model = model.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper],\n                                                            epochs = 25, verbose = 1, validation_data = (X_test, y_test))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:43:29.605045Z","iopub.execute_input":"2021-12-16T11:43:29.605363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (10, 5))\naxes[0].plot(range(1, len(model.history.history['accuracy']) + 1), model.history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy')\naxes[0].plot(range(1, len(model.history.history['val_accuracy']) + 1), model.history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\naxes[0].set_xlabel('Epochs', fontsize = 14)\naxes[0].set_ylabel('Accuracy',fontsize = 14)\naxes[0].set_title('CNN Dropout Accuracy Trainig VS Testing', fontsize = 14)\naxes[0].legend(loc = 'best')\naxes[1].plot(range(1, len(model.history.history['loss']) + 1), model.history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\naxes[1].plot(range(1, len(model.history.history['val_loss']) + 1), model.history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\naxes[1].set_xlabel('Epochs', fontsize = 14)\naxes[1].set_ylabel('Loss',fontsize = 14)\naxes[1].set_title('CNN Dropout Loss Trainig VS Testing', fontsize = 14)\naxes[1].legend(loc = 'best')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.76899Z","iopub.status.idle":"2021-12-16T11:33:17.769992Z","shell.execute_reply.started":"2021-12-16T11:33:17.769556Z","shell.execute_reply":"2021-12-16T11:33:17.769621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST","metadata":{}},{"cell_type":"code","source":"# labels is the image array\ntest_image = []\ni = 0\nfig, ax = plt.subplots(1, 20, figsize = (50,50 ))\n\nfiles = os.listdir('/home/jupyter/TestImages')\nnums = np.random.randint(low=1, high=len(files), size=20)\nfor i in range(20):\n    print ('Image number:',i)\n    img = cv2.imread('/home/jupyter/TestImages/'+files[nums[i]])\n    #img = color.rgb2gray(img)\n    img = img[50:,120:-50]\n    img = cv2.resize(img,(224,224))\n    test_image.append(img)\n    ax[i].imshow(img,cmap = 'gray')\n    plt.show\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.771825Z","iopub.status.idle":"2021-12-16T11:33:17.772874Z","shell.execute_reply.started":"2021-12-16T11:33:17.772521Z","shell.execute_reply":"2021-12-16T11:33:17.772555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = []\n\nfor img in test_image:\n    test.append(img)\n    \nmodel.load_weights('mobilenet_sgd_nolayers.hdf5')\n\n\ntest = np.array(test).reshape(-1,224,224,3)\nprediction = model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.774733Z","iopub.status.idle":"2021-12-16T11:33:17.775777Z","shell.execute_reply.started":"2021-12-16T11:33:17.775424Z","shell.execute_reply":"2021-12-16T11:33:17.775458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.777616Z","iopub.status.idle":"2021-12-16T11:33:17.77889Z","shell.execute_reply.started":"2021-12-16T11:33:17.778499Z","shell.execute_reply":"2021-12-16T11:33:17.778532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = { \"C0\": \"safe driving\",\n\"C1\": \"texting - right\",\n\"C2\": \"talking on the phone - right\",\n\"C3\": \"texting - left\",\n\"C4\": \"talking on the phone - left\",\n\"C5\": \"operating the radio\",\n\"C6\": \"drinking\",\n\"C7\": \"reaching behind\",\n\"C8\": \"hair and makeup\",\n\"C9\": \"talking to passenger\" }","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.780593Z","iopub.status.idle":"2021-12-16T11:33:17.781311Z","shell.execute_reply.started":"2021-12-16T11:33:17.781003Z","shell.execute_reply":"2021-12-16T11:33:17.781037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels is the image array\ni = 0\nfig, ax = plt.subplots(20, 1, figsize = (100,100))\n\nfor i in range(20):\n    ax[i].imshow(test[i].squeeze())\n    predicted_class = 'C'+str(np.where(prediction[i] == np.amax(prediction[i]))[0][0])\n    ax[i].set_title(tags[predicted_class])\n    plt.show\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:33:17.784873Z","iopub.status.idle":"2021-12-16T11:33:17.785813Z","shell.execute_reply.started":"2021-12-16T11:33:17.78545Z","shell.execute_reply":"2021-12-16T11:33:17.785498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}