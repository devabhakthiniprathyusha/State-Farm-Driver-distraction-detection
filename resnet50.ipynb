{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Implementing ResNet for Image Classification:**\n\nThis notebook has portions taken from published source Jovian and Kaggle and has been modified extended by modifying the classification section as well as changing the image preprocessing. to the State Farm Distracted Driver Detection dataset.\n\nThe dataset that will be worked with can be found on Kaggle.com (https://www.kaggle.com/c/state-farm-distracted-driver-detection/data).\n\nThere are 10 different classes, and 79.7 thousand images. The classes are safe driving, texting with right hand, talking on the phone with right hand, texting with left hand, talking on the phone with left hand, operating the radio, drinking, reaching behind, hair and makeup and talking to passenger. The data is split into a test set and a training set. The data is split on the drivers, meaning that a driver can only appear in one of the training set or the testing set. The goal is to classify what the driver is doing in each picture, and if they are distracted or not.\n\nUsing this Dataset, Iâ€™m going to present results of Residual neural networks (ResNet) used for Image classification to test the accuracy they present for these images, first creating it piece by piece and then importing and adapting a pre trained ResNet.","metadata":{"execution":{"iopub.status.busy":"2021-11-24T13:11:32.643725Z","iopub.execute_input":"2021-11-24T13:11:32.644021Z","iopub.status.idle":"2021-11-24T13:11:37.067149Z","shell.execute_reply.started":"2021-11-24T13:11:32.643963Z","shell.execute_reply":"2021-11-24T13:11:37.06624Z"}}},{"cell_type":"markdown","source":"1. import libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:19.311032Z","iopub.execute_input":"2021-12-16T11:50:19.311775Z","iopub.status.idle":"2021-12-16T11:50:23.165293Z","shell.execute_reply.started":"2021-12-16T11:50:19.311677Z","shell.execute_reply":"2021-12-16T11:50:23.164524Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:23.166952Z","iopub.execute_input":"2021-12-16T11:50:23.167218Z","iopub.status.idle":"2021-12-16T11:50:23.175666Z","shell.execute_reply.started":"2021-12-16T11:50:23.167183Z","shell.execute_reply":"2021-12-16T11:50:23.174852Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"2. get data","metadata":{}},{"cell_type":"code","source":"sample_path = \"/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\"\nimgs_list_path = \"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\"\ntrain_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:23.177090Z","iopub.execute_input":"2021-12-16T11:50:23.177615Z","iopub.status.idle":"2021-12-16T11:50:23.183089Z","shell.execute_reply.started":"2021-12-16T11:50:23.177579Z","shell.execute_reply":"2021-12-16T11:50:23.182253Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1.Check data distribution","metadata":{}},{"cell_type":"code","source":"driver_imgs_list = pd.read_csv(imgs_list_path)\ndriver_imgs_list.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:23.185114Z","iopub.execute_input":"2021-12-16T11:50:23.185370Z","iopub.status.idle":"2021-12-16T11:50:23.238704Z","shell.execute_reply.started":"2021-12-16T11:50:23.185337Z","shell.execute_reply":"2021-12-16T11:50:23.238049Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"os.listdir(train_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:23.239876Z","iopub.execute_input":"2021-12-16T11:50:23.240111Z","iopub.status.idle":"2021-12-16T11:50:23.251272Z","shell.execute_reply.started":"2021-12-16T11:50:23.240078Z","shell.execute_reply":"2021-12-16T11:50:23.250629Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def pair_sort(className,values):\n    for j in range(0,len(className)-1):\n        for i in range(0,len(className)-1):\n            if values[i] > values[i+1]:\n                temp =  values[i+1]\n                values[i+1] = values[i]\n                values[i] = temp\n\n                N_temp =  className[i+1]\n                className[i+1] = className[i]\n                className[i] = N_temp\n    \n    return className,values","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:23.291877Z","iopub.execute_input":"2021-12-16T11:50:23.292209Z","iopub.status.idle":"2021-12-16T11:50:23.298423Z","shell.execute_reply.started":"2021-12-16T11:50:23.292174Z","shell.execute_reply":"2021-12-16T11:50:23.297651Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\nfigure(num=None, figsize=(15, 5), dpi=80, facecolor='w', edgecolor='k')\n\nclass_names = np.unique(driver_imgs_list['classname'])\nclass_image_list = [len(driver_imgs_list[driver_imgs_list['classname'] == current_class]) for current_class in class_names]\n\nclass_names,class_image_list=  pair_sort(class_names,class_image_list)\n\n#plt.figure()\nplt.suptitle('Number of images per Class')\nplt.bar(class_names,class_image_list,color=(0.2, 0.4, 0.6, 0.6))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:23.667464Z","iopub.execute_input":"2021-12-16T11:50:23.668125Z","iopub.status.idle":"2021-12-16T11:50:23.964944Z","shell.execute_reply.started":"2021-12-16T11:50:23.668085Z","shell.execute_reply":"2021-12-16T11:50:23.964317Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\nsub_names = np.unique(driver_imgs_list['subject'])\nsub_image_list = [len(driver_imgs_list[driver_imgs_list['subject'] == current_sub]) for current_sub in sub_names]\nsub_names,sub_image_list=  pair_sort(sub_names,sub_image_list)\n\nfigure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n\ny_pos = np.arange(len(sub_names))\n# Create horizontal bars\nplt.barh(y_pos, sub_image_list,color=(0.2, 0.4, 0.6, 0.6))\n \n# Create names on the y-axis\nplt.yticks(y_pos,sub_names )\nplt.suptitle('Number of images per subject')\n\n# Show graphic\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:24.051425Z","iopub.execute_input":"2021-12-16T11:50:24.051991Z","iopub.status.idle":"2021-12-16T11:50:24.469934Z","shell.execute_reply.started":"2021-12-16T11:50:24.051951Z","shell.execute_reply":"2021-12-16T11:50:24.469281Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"img_width,img_height = (256,256)\nmodel_input_shape = (img_width,img_height,3)\nbatch_size = 16\ninput_image = (img_width,img_height)\n\ndef load_image(path):\n    read_path = train_path+\"/\"+path\n    image = Image.open(read_path)\n    image = image.resize(input_image)\n    \n    return np.asarray(image)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:24.471446Z","iopub.execute_input":"2021-12-16T11:50:24.471763Z","iopub.status.idle":"2021-12-16T11:50:24.477035Z","shell.execute_reply.started":"2021-12-16T11:50:24.471725Z","shell.execute_reply":"2021-12-16T11:50:24.476387Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def show_images(image_ids,class_names):\n    pixels = [load_image(path) for path in image_ids]\n    \n    num_of_images = len(image_ids)\n    \n    fig, axes = plt.subplots(\n        1, \n        num_of_images, \n        figsize=(5 * num_of_images, 5 * num_of_images),\n        \n    )\n   \n    \n    for i, image_pixels in enumerate(pixels):\n        axes[i].imshow(image_pixels)\n        axes[i].axis(\"off\")\n        axes[i].set_title(class_names[i])","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:24.836480Z","iopub.execute_input":"2021-12-16T11:50:24.837095Z","iopub.status.idle":"2021-12-16T11:50:24.844693Z","shell.execute_reply.started":"2021-12-16T11:50:24.837058Z","shell.execute_reply":"2021-12-16T11:50:24.844020Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## 2.Plot class images","metadata":{}},{"cell_type":"code","source":"sub_names_imgs = [ current_class+\"/\"+driver_imgs_list[driver_imgs_list['classname'] == current_class]['img'].values[0] for current_class in class_names]\n\nshow_images(sub_names_imgs[:5],class_names[:5])\nshow_images(sub_names_imgs[5:],class_names[5:])","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:28.168876Z","iopub.execute_input":"2021-12-16T11:50:28.169401Z","iopub.status.idle":"2021-12-16T11:50:29.396597Z","shell.execute_reply.started":"2021-12-16T11:50:28.169364Z","shell.execute_reply":"2021-12-16T11:50:29.396013Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":" ## 3. Split and load Train/Validation ","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"\ntest_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:39.995633Z","iopub.execute_input":"2021-12-16T11:50:39.995922Z","iopub.status.idle":"2021-12-16T11:50:40.000624Z","shell.execute_reply.started":"2021-12-16T11:50:39.995889Z","shell.execute_reply":"2021-12-16T11:50:39.999756Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\n\nsplit_rate = 0.8 # take 80% of the data as train, and 20% as val\nfor current_class in class_names:\n    select_df = driver_imgs_list[driver_imgs_list['classname'] == current_class ]\n    image_list = select_df['img'].values\n    train_amount = int(len(image_list)*split_rate)\n    train_list = image_list[:train_amount]\n    val_list = image_list[train_amount:]\n    \n    for filename in train_list:\n        x_train.append(load_image(current_class+\"/\"+filename))\n        y_train.append(current_class.replace('c',''))\n\n    for filename in val_list:\n        x_val.append(load_image(current_class+\"/\"+filename))\n        y_val.append(current_class.replace('c',''))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:50:40.444297Z","iopub.execute_input":"2021-12-16T11:50:40.445011Z","iopub.status.idle":"2021-12-16T11:55:55.276907Z","shell.execute_reply.started":"2021-12-16T11:50:40.444964Z","shell.execute_reply":"2021-12-16T11:55:55.276107Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 4. Encode Labels","metadata":{}},{"cell_type":"code","source":"x_train = np.asarray(x_train)\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\nx_val = np.asarray(x_val)\ny_val =tf.keras.utils.to_categorical(y_val, num_classes=10)\nprint(\"Train x Shape: \",x_train.shape)\nprint(\"Test x Shape: \",x_val.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:55.278522Z","iopub.execute_input":"2021-12-16T11:55:55.278778Z","iopub.status.idle":"2021-12-16T11:55:57.517749Z","shell.execute_reply.started":"2021-12-16T11:55:55.278742Z","shell.execute_reply":"2021-12-16T11:55:57.516844Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(\"Train y Shape: \",y_train.shape)\nprint(\"Test y Shape: \",y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:57.519108Z","iopub.execute_input":"2021-12-16T11:55:57.519425Z","iopub.status.idle":"2021-12-16T11:55:57.531248Z","shell.execute_reply.started":"2021-12-16T11:55:57.519386Z","shell.execute_reply":"2021-12-16T11:55:57.527954Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 5. Create Model\n","metadata":{}},{"cell_type":"code","source":"base_model  = tf.keras.applications.resnet.ResNet50(include_top = False,\n                                                  weights = 'imagenet',\n                                                  input_shape = model_input_shape)\nbase_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:57.532887Z","iopub.execute_input":"2021-12-16T11:55:57.534316Z","iopub.status.idle":"2021-12-16T11:56:01.898236Z","shell.execute_reply.started":"2021-12-16T11:55:57.534265Z","shell.execute_reply":"2021-12-16T11:56:01.896613Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# x = base_model.output\n# x = tf.keras.layers.Flatten()(x)\n# x = tf.keras.layers.Dropout(0.5)(x)\n\n# output =tf.keras.layers.Dense(units = len(class_names),activation = tf.nn.softmax)(x)\n# model = tf.keras.models.Model(inputs=base_model.inputs, outputs=output)\n\n# model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n#               metrics=['accuracy'])\n\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:56:01.903274Z","iopub.execute_input":"2021-12-16T11:56:01.905894Z","iopub.status.idle":"2021-12-16T11:56:01.912608Z","shell.execute_reply.started":"2021-12-16T11:56:01.905841Z","shell.execute_reply":"2021-12-16T11:56:01.911479Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# calculating class weights which are inversely proportional to number of training examples\nclasses, counts = np.unique(np.argmax(y_train, axis = 1), return_counts = True)\ntotal = sum(counts)\nratios = 1/(counts/total)\n\nclass_weights = dict()\n\nfor i in range(10):\n    class_weights[i] = ratios[i]\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:56:01.915055Z","iopub.execute_input":"2021-12-16T11:56:01.915568Z","iopub.status.idle":"2021-12-16T11:56:01.935812Z","shell.execute_reply.started":"2021-12-16T11:56:01.915524Z","shell.execute_reply":"2021-12-16T11:56:01.932313Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#model 2\nx = base_model.output\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Dense(units = 512, activation = tf.nn.relu)(x)\nx = tf.keras.layers.Dense(units = 256, activation = tf.nn.relu)(x)\nx = tf.keras.layers.Dropout(0.25)(x)\n\noutput =tf.keras.layers.Dense(units = len(class_names),activation = tf.nn.softmax)(x)\nmodel = tf.keras.models.Model(inputs=base_model.inputs, outputs=output)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:56:01.939970Z","iopub.execute_input":"2021-12-16T11:56:01.940464Z","iopub.status.idle":"2021-12-16T11:56:02.180503Z","shell.execute_reply.started":"2021-12-16T11:56:01.940385Z","shell.execute_reply":"2021-12-16T11:56:02.179728Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50\ndef lr_schedule(epoch,lr):\n    # Learning Rate Schedule\n\n    lr = lr\n    total_epochs = num_epochs\n\n    check_1 = int(total_epochs * 0.9)\n    check_2 = int(total_epochs * 0.8)\n    check_3 = int(total_epochs * 0.6)\n    check_4 = int(total_epochs * 0.4)\n\n    if epoch > check_1:\n        lr *= 1e-4\n    elif epoch > check_2:\n        lr *= 1e-3\n    elif epoch > check_3:\n        lr *= 1e-2\n    elif epoch > check_4:\n        lr *= 1e-1\n\n    print(\"[+] Current Lr rate : {} \".format(lr))\n    return lr\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:56:02.183934Z","iopub.execute_input":"2021-12-16T11:56:02.185278Z","iopub.status.idle":"2021-12-16T11:56:02.199073Z","shell.execute_reply.started":"2021-12-16T11:56:02.185196Z","shell.execute_reply":"2021-12-16T11:56:02.198197Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n      x = x_train,y=y_train,\n      validation_data=(x_val,y_val),\n      steps_per_epoch=16, # will reduce the training data to 128 images per class\n      batch_size = 8,\n      epochs=20,\n    class_weight=class_weights,\n    callbacks = [lr_callback],\n      verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:56:02.204220Z","iopub.execute_input":"2021-12-16T11:56:02.207039Z","iopub.status.idle":"2021-12-16T12:02:13.137221Z","shell.execute_reply.started":"2021-12-16T11:56:02.206992Z","shell.execute_reply":"2021-12-16T12:02:13.135715Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## 6. Model Evaluation","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n\nax[0].set_title('Training Loss')\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\n\nax[1].set_title('Validation Loss')\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])","metadata":{"execution":{"iopub.status.busy":"2021-12-16T12:02:13.141064Z","iopub.execute_input":"2021-12-16T12:02:13.141288Z","iopub.status.idle":"2021-12-16T12:02:13.497708Z","shell.execute_reply.started":"2021-12-16T12:02:13.141255Z","shell.execute_reply":"2021-12-16T12:02:13.497020Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-12-16T12:02:13.498944Z","iopub.execute_input":"2021-12-16T12:02:13.499358Z","iopub.status.idle":"2021-12-16T12:02:14.521451Z","shell.execute_reply.started":"2021-12-16T12:02:13.499320Z","shell.execute_reply":"2021-12-16T12:02:14.520688Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(model, x_val, y_val)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T12:02:14.522642Z","iopub.execute_input":"2021-12-16T12:02:14.522911Z","iopub.status.idle":"2021-12-16T12:02:15.059592Z","shell.execute_reply.started":"2021-12-16T12:02:14.522876Z","shell.execute_reply":"2021-12-16T12:02:15.058448Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}